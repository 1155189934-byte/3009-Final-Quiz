{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MNbBQom4sp7x",
        "NmwvX0l0nyZJ",
        "q0Ji7zWjkqTM",
        "vjoYf4QTydLN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUHK-STAT3009: Homework 2 - More SVD Models **(due Nov 13)**\n"
      ],
      "metadata": {
        "id": "scVebJIongBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1: Basic Usage of SVD for Rating Prediction**"
      ],
      "metadata": {
        "id": "MNbBQom4sp7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the SVD Class**\n",
        "\n",
        "Download the `SVD` class from our GitHub repository: https://github.com/statmlben/CUHK-STAT3009/blob/main/src/TabRS.py.\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "We will use a synthetic dataset to demonstrate the basic usage of SVD for rating prediction. The dataset consists of user ratings for various items, represented by the following DataFrame:\n",
        "```python\n",
        "import pandas as pd\n",
        "data = {\n",
        "    'user_id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "    'item_id': [1, 2, 1, 3, 1, 3, 2, 3, 2, 3],\n",
        "    'rating': [5, 3, 4, 2, 1, 3, 4, 5, 2, 3]}\n",
        "df = pd.DataFrame(data)\n",
        "```\n",
        "\n",
        "**Task**\n",
        "\n",
        "Your task is to train an SVD model with $K = 2$ and $\\lambda = 0.001$ using the provided dataset and predict the ratings for the following user-item pairs:\n",
        "\n",
        "* `user_id` = 2, `item_id` = 2\n",
        "* `user_id` = 5, `item_id` = 1\n",
        "\n",
        "Implement the SVD model, train it on the dataset, and provide the predicted ratings for the specified user-item pairs.\n",
        "\n",
        "> The correctness of the implementation will be evaluated based on the code structure and logic, not on the final evaluation results."
      ],
      "metadata": {
        "id": "vPMcFQampnOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/src/TabRS.py"
      ],
      "metadata": {
        "id": "dgQvEbiocZu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Your solution here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from TabRS import SVD\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "# åŽŸå§‹ synthetic æ•°æ®\n",
        "data = {\n",
        "    'user_id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "    'item_id': [1, 2, 1, 3, 1, 3, 2, 3, 2, 3],\n",
        "    'rating': [5, 3, 4, 2, 1, 3, 4, 5, 2, 3]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# ðŸš© å…³é”®ä¸€æ­¥ï¼šæ”¹æˆ 0-based ç´¢å¼•ï¼ˆå¿…é¡»ï¼‰\n",
        "df[\"user_idx\"] = df[\"user_id\"] - 1   # 1~5 â†’ 0~4\n",
        "df[\"item_idx\"] = df[\"item_id\"] - 1   # 1~3 â†’ 0~2\n",
        "\n",
        "# è¿™é‡Œæ²¡æœ‰çœŸæ­£çš„ train/testï¼Œå°±æŒ‰ä½ ä¹ æƒ¯çš„å˜é‡åæ¥\n",
        "train = df.copy()\n",
        "test = df.copy()\n",
        "\n",
        "# æŒ‰ä½ å–œæ¬¢çš„æ ¼å¼å†™ X_train / X_test\n",
        "X_train = train[[\"user_idx\", \"item_idx\"]].values\n",
        "y_train = train[\"rating\"].values\n",
        "\n",
        "X_test = test[[\"user_idx\", \"item_idx\"]].values\n",
        "y_test = test[\"rating\"].values\n",
        "\n",
        "# ä»ç„¶ç”¨ union çš„å†™æ³•ç®— n_users / n_items\n",
        "n_users = len(set(X_train[:,0]).union(X_test[:,0]))  # = 5\n",
        "n_items = len(set(X_train[:,1]).union(X_test[:,1]))  # = 3\n",
        "\n",
        "model = SVD(\n",
        "    n_users=n_users,\n",
        "    n_items=n_items,\n",
        "    K=2,\n",
        "    lam=0.001\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# é¢˜ç›®è¦æ±‚é¢„æµ‹çš„ä¸¤ä¸ª pairï¼ˆå…ˆç”¨åŽŸå§‹ id å†™ï¼‰\n",
        "pairs_raw = np.array([\n",
        "    [2, 2],  # user_id=2, item_id=2\n",
        "    [5, 1]   # user_id=5, item_id=1\n",
        "])\n",
        "\n",
        "# åŒæ ·è¦è½¬æˆ 0-based\n",
        "pairs_idx = pairs_raw - 1   # [[1,1], [4,0]]\n",
        "\n",
        "y_pred = model.predict(pairs_idx)\n",
        "\n",
        "for (u, i), r in zip(pairs_raw, y_pred):\n",
        "    print(f\"user_id={u}, item_id={i} -> predicted rating = {r:.4f}\")\n"
      ],
      "metadata": {
        "id": "6WwTgM38rKsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0d316d-1a64-4348-8240-50408e458a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting Reg-SVD: K: 2, lam: 0.00100\n",
            "RegSVD-ALS: 0; obj: 0.019; rmse:0.015, diff: 12.303\n",
            "RegSVD-ALS: 1; obj: 0.018; rmse:0.014, diff: 0.000\n",
            "RegSVD-ALS: 2; obj: 0.018; rmse:0.014, diff: 0.000\n",
            "RegSVD-ALS: 3; obj: 0.017; rmse:0.013, diff: 0.000\n",
            "RegSVD-ALS: 4; obj: 0.017; rmse:0.012, diff: 0.000\n",
            "RegSVD-ALS: 5; obj: 0.017; rmse:0.012, diff: 0.000\n",
            "RegSVD-ALS: 6; obj: 0.016; rmse:0.011, diff: 0.000\n",
            "RegSVD-ALS: 7; obj: 0.016; rmse:0.011, diff: 0.000\n",
            "RegSVD-ALS: 8; obj: 0.016; rmse:0.011, diff: 0.000\n",
            "RegSVD-ALS: 9; obj: 0.016; rmse:0.010, diff: 0.000\n",
            "user_id=2, item_id=2 -> predicted rating = 3.9555\n",
            "user_id=5, item_id=1 -> predicted rating = 4.7349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q2: Lasso-SVD Recommender Systems**"
      ],
      "metadata": {
        "id": "NmwvX0l0nyZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data**\n",
        "\n",
        "In this task, you will implement a user-item average based recommender system using the Netflix dataset from the CUHK-STAT3009 GitHub repository.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Netflix dataset from the CUHK-STAT3009 GitHub repository\n",
        "# Repository link: https://github.com/statmlben/CUHK-STAT3009/tree/main/dataset/netflix\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "\n",
        "# Convert DataFrame to NumPy arrays\n",
        "```\n",
        "\n",
        "**Lasso Regression**\n",
        "\n",
        "Given a dataset of feature-vectors $\\mathbf{x}_i$ and corresponding ground truth scores $y_i$, Lasso regression seeks a sparse solution by minimizing the following objective function:\n",
        "\n",
        "$$\\text{argmin}_{\\mathbf{\\beta}} \\ \\frac{1}{n} \\sum_{i=1}^n ( y_i - \\mathbf{\\beta}^T \\mathbf{x}_i )^2 + \\lambda \\| \\mathbf{\\beta} \\|_1, \\quad \\text{where } \\| \\mathbf{\\beta} \\|_1 = \\sum_{j=1}^p |\\beta_j|$$\n",
        "\n",
        "This can be efficiently solved using `sklearn.linear_model.Lasso` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)).\n",
        "\n",
        "### **Task: Lasso Matrix Factorization (Lasso_SVD)**\n",
        "\n",
        "**Objective**\n",
        "\n",
        "Implement a Lasso_SVD recommender system by solving the following optimization problem:\n",
        "\n",
        "$$\\boxed{(\\widehat{\\mathbf P}, \\widehat{\\mathbf Q}) = \\text{argmin}_{\\mathbf{P}, \\mathbf{Q} } \\frac{1}{|\\Omega|} \\sum_{(u,i) \\in \\Omega} ( r_{ui} - \\mathbf{p}^\\intercal_u \\mathbf{q}_i  )^2 + \\lambda \\big(  \\sum_{u=1}^n \\|\\mathbf{p}_u\\|_1 + \\sum_{i=1}^m \\|\\mathbf{q}_i\\|_1 \\big)}$$\n",
        "\n",
        "**Implementation**\n",
        "\n",
        "Create a class `Lasso_SVD` with two methods:\n",
        "\n",
        "1. `Lasso_SVD.fit`: Fit the parameters $\\mathbf{P}$ and $\\mathbf{Q}$ by solving the optimization problem above using Lasso regression.\n",
        "2. `Lasso_SVD.predict`: Predict ratings using the fitted parameters: $\\widehat{r}_{ui} = \\widehat{\\mathbf{p}}^T_u \\widehat{\\mathbf{q}}_i$\n",
        "\n",
        "**Hint**: Use Alternative Least Square (ALS) logic, where each subproblem is a Lasso regression that can be solved using `sklearn.linear_model.Lasso` (previously, we use `sklearn.linear_model.Ridge`).\n",
        "\n",
        "**Evaluation**\n",
        "\n",
        "Print the Root Mean Squared Error (RMSE) for the testing data using the following hyperparameters:\n",
        "\n",
        "* $(\\lambda = 0.1, K = 3)$\n",
        "* $(\\lambda = 0.3, K = 5)$\n",
        "\n",
        "> Implement the `Lasso_SVD` class with the required methods. The correctness of the implementation will be evaluated based on the code structure and logic, not on the final evaluation results."
      ],
      "metadata": {
        "id": "bmWa31GcoeYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your solution here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "train.head()\n",
        "X_train = train[[\"user_id\", \"movie_id\"]].values\n",
        "y_train = train[\"rating\"].values\n",
        "X_test = test[[\"user_id\", \"movie_id\"]].values\n",
        "y_test = test[\"rating\"].values\n",
        "n_users = len(set(X_train[:,0]).union(X_test[:,0]))\n",
        "n_items = len(set(X_train[:,1]).union(X_test[:,1]))\n"
      ],
      "metadata": {
        "id": "4MawiY3rn-oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso,Ridge\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import mean_squared_error\n",
        "class Lasso_SVD(BaseEstimator):\n",
        "  def __init__(self, n_user, n_item, K=5, lam=0.01, epsilon=1, iterNum=10, tol=1e-4):\n",
        "    self.n_user = n_user\n",
        "    self.n_item = n_item\n",
        "\n",
        "    self.K = K\n",
        "    self.lam = lam\n",
        "    self.P = np.random.randn(n_user, K)\n",
        "    self.Q = np.random.randn(n_item, K)\n",
        "    self.iterNum = iterNum\n",
        "    self.tol = tol\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n_obs = len(X)\n",
        "    diff = 1.0\n",
        "    obj_tmp = self.obj(X, y)\n",
        "\n",
        "    for h in range(self.iterNum):\n",
        "      if diff < self.tol:\n",
        "        break\n",
        "      for i in range(self.n_item):\n",
        "        index_tmp = np.where(X[:,1] == i)[0]\n",
        "        if len(index_tmp) == 0:\n",
        "          self.Q[i] = np.zeros(self.K)\n",
        "        else:\n",
        "          y_tmp = y[index_tmp]\n",
        "          P_tmp = self.P[X[index_tmp,0]]\n",
        "          clf_tmp = Lasso(alpha=self.lam*n_obs, fit_intercept=False)\n",
        "          clf_tmp.fit(X=P_tmp, y=y_tmp)\n",
        "          self.Q[i] = clf_tmp.coef_\n",
        "\n",
        "      for u in range(self.n_user):\n",
        "        index_tmp = np.where(X[:,0] == u)[0]\n",
        "        if len(index_tmp) == 0:\n",
        "          self.P[u] = np.zeros(self.K)\n",
        "        else:\n",
        "          y_tmp = y[index_tmp]\n",
        "          Q_tmp = self.Q[X[index_tmp,1]]\n",
        "          clf_tmp = Lasso(alpha=self.lam*n_obs,fit_intercept=False)\n",
        "          clf_tmp.fit(X=Q_tmp, y=y_tmp)\n",
        "          self.P[u] = clf_tmp.coef_\n",
        "\n",
        "      obj_old = obj_tmp\n",
        "      obj_tmp = self.obj(X, y)\n",
        "      diff = obj_old - obj_tmp\n",
        "\n",
        "      print(f\"Lasso_SVD-BCD: step: {h}; obj: {obj_tmp}, diff: {diff}\")\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    y_pred = []\n",
        "    for x_tmp in X:\n",
        "      user_id_tmp = x_tmp[0]\n",
        "      item_id_tmp = x_tmp[1]\n",
        "\n",
        "      y_pred_tmp = self.P[user_id_tmp] @ self.Q[item_id_tmp]\n",
        "      y_pred.append(y_pred_tmp)\n",
        "    return np.array(y_pred)\n",
        "\n",
        "  def obj(self, X, y):\n",
        "    y_pred = self.predict(X)\n",
        "    mse = mean_squared_error(y,y_pred)\n",
        "    pen = np.sum(self.P**2) + np.sum(self.Q**2)\n",
        "    return mse + self.lam * pen\n"
      ],
      "metadata": {
        "id": "g69q5USRes2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1= Lasso_SVD(n_users, n_items, K=3, lam=0.1)\n",
        "model2= Lasso_SVD(n_users, n_items, K=5, lam=0.3)\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "model2.fit(X_train, y_train)\n",
        "y_pred2 = model2.predict(X_test)\n",
        "print(f'RMSE for (Î»=0.1,K=3): {rmse(y_pred1, y_test)}')\n",
        "print(f'RMSE for (Î»=0.3,K=5): {rmse(y_pred2, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qUh-kOpfneT",
        "outputId": "f5f92fd1-366a-4990-9f7d-57b4f977f2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso_SVD-BCD: step: 0; obj: 14.296202185258302, diff: 1674.976982855409\n",
            "Lasso_SVD-BCD: step: 1; obj: 14.296202185258302, diff: 0.0\n",
            "Lasso_SVD-BCD: step: 0; obj: 14.296202185258302, diff: 8513.790390942793\n",
            "Lasso_SVD-BCD: step: 1; obj: 14.296202185258302, diff: 0.0\n",
            "RMSE for (Î»=0.1,K=3): 3.7870676665868332\n",
            "RMSE for (Î»=0.3,K=5): 3.7870676665868332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q3: Kaggle Submission by Neural Networks**"
      ],
      "metadata": {
        "id": "q0Ji7zWjkqTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**\n",
        "\n",
        "- Create an arbitrary Neural Network with Dense layers and Make a Submission to the Kaggle Competition: [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview)\n",
        "\n",
        "- Paste the submission results screenshot into this Jupyter Notebook."
      ],
      "metadata": {
        "id": "i_I8k7XEk0Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your submission result here"
      ],
      "metadata": {
        "id": "MrE96ktWky9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q4 (Bonus): Parallel Alternating Least Squares (ALS) for Matrix Factorization**"
      ],
      "metadata": {
        "id": "vjoYf4QTydLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Background**\n",
        "\n",
        "Recall the item and user updates for `SVD` based on ALS:\n",
        "\n",
        "$$\\mathbf{q}^{(l+1)}_i = \\left(\\sum_{u \\in \\mathcal{U}_i} \\mathbf{p}^{(l)}_u (\\mathbf{p}^{(l)}_u)^T + \\lambda |\\Omega| \\mathbf{I}\\right)^{-1} \\sum_{u \\in \\mathcal{U}_i} r_{ui} \\mathbf{p}^{(l)}_u$$\n",
        "\n",
        "$$\\mathbf{p}^{(l+1)}_u = \\left(\\sum_{i \\in \\mathcal{I}_u} \\mathbf{q}^{(l+1)}_i (\\mathbf{q}^{(l+1)}_i)^\\intercal + \\lambda |\\Omega| \\mathbf{I}\\right)^{-1} \\sum_{i \\in \\mathcal{I}_u} r_{ui} \\mathbf{q}^{(l+1)}_i$$\n",
        "\n",
        "The key observation is that the updates for user-$u$ and item-$i$ are independent of other users and items, respectively. Therefore, they can be performed in parallel.\n",
        "\n",
        "Suppose you have 100 users to update, the basic ALS updates user 1, user 2, ..., user 100 sequentially in a loop. Now, suppose you have 100 CPUs, the parallel ALS can update 100 users simultaneously by distributing each user to a different CPU, significantly reducing the computation time.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "1. **Parallelize the `SVD.fit` method**: Revise the `SVD.fit` method (available in [repo](https://github.com/statmlben/CUHK-STAT3009/blob/main/src/TabRS.py)) to allow parallel updating of $\\mathbf{p}_u$ and $\\mathbf{q}_i$ using Python libraries such as [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) or [pymp](https://github.com/classner/pymp).\n",
        "2. **Compare computation times**: Compare the computation time for `SVD.fit` with and without parallel computing using the `%%time` magic command (see [ref](https://stackoverflow.com/questions/32565829/simple-way-to-measure-cell-execution-time-in-ipython-notebook))."
      ],
      "metadata": {
        "id": "qBM7KfZJerF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of CPUs in your PC/Node\n",
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUx5wVsYfLWp",
        "outputId": "3544b18f-75a5-4536-d624-acf93e510407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You solution here"
      ],
      "metadata": {
        "id": "K0c5Z3TEMm6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}